{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a49406",
   "metadata": {},
   "source": [
    "# **Redes Neurais**\n",
    "## **Modelo 3 - Variational Autoencoder (VAE)**\n",
    "\n",
    "- Aluno: Tales Miguel\n",
    "- RA: 140247\n",
    "\n",
    "- Professor Dr. Marcos G. Quiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1bbfd",
   "metadata": {},
   "source": [
    "## **Instruções**\n",
    "\n",
    "▸Selecionar 2 datasets (rotulados) -----> Se for um relatório detalhado, pode usar apenas 1 dataset\n",
    "\n",
    "▸Treinar modelos VAEs:\n",
    "  - Ajustar o melhor modelo (topologia) segundo a função de custo (conjunto validação)\n",
    "\n",
    "▸Explorar o espaço latente:\n",
    "  - Gerar gráficos com a projeção do espaço latente em 2D (PCA)\n",
    "  - Usar os rótulos na projeção\n",
    "\n",
    "▸Algumas questões:\n",
    "  1. Há formação de clusters no espaço latente?\n",
    "  2. Há separação dos rótulos no espaço latente?\n",
    "  3. A projeção ilustra quanto da variância?\n",
    "\n",
    "▸ Adicional (opcional): Enviesar a formação do espaço latente com os exemplos rotulados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b54e0d",
   "metadata": {},
   "source": [
    "## **1. Escolha do Dataset e Pré-processamento dos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aedc52",
   "metadata": {},
   "source": [
    "### **1.1. Dataset Escolhido - EMNIST Letters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744eab4b",
   "metadata": {},
   "source": [
    "**Dataset**: EMNIST Letters  \n",
    "**Fonte**: Extended MNIST (Cohen et al., 2017) | [Acesso via TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/emnist)\n",
    "\n",
    "**Características:**\n",
    "- **Samples**: ~145.000 imagens (124.800 treino + 20.800 teste)\n",
    "- **Dimensões**: 28x28 pixels (grayscale)\n",
    "- **Features**: 784 (28×28 pixels normalizados)\n",
    "- **Classes**: 26 letras maiúsculas (A-Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1f0f4",
   "metadata": {},
   "source": [
    "### **1.2. Imports e Pré-processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde926de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 18:26:18.519349: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-06 18:26:18.533126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762464378.545940   20537 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762464378.548639   20537 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762464378.554105   20537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762464378.554112   20537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762464378.554113   20537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762464378.554113   20537 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-06 18:26:18.556193: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'runtime_version' from 'google.protobuf' (/home/tales/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/google/protobuf/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecomposition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m silhouette_score, davies_bouldin_score, calinski_harabasz_score\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, Model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/__init__.py:49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     47\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_sys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[32m     25\u001b[39m stacks = threading.local()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcontextlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:33\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m typing \u001b[38;5;28;01mas\u001b[39;00m npt\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m message\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m attr_value_pb2\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m full_type_pb2\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m function_pb2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/tensorflow/core/framework/attr_value_pb2.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor \u001b[38;5;28;01mas\u001b[39;00m _descriptor\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m descriptor_pool \u001b[38;5;28;01mas\u001b[39;00m _descriptor_pool\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m runtime_version \u001b[38;5;28;01mas\u001b[39;00m _runtime_version\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m symbol_database \u001b[38;5;28;01mas\u001b[39;00m _symbol_database\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprotobuf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minternal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m builder \u001b[38;5;28;01mas\u001b[39;00m _builder\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'runtime_version' from 'google.protobuf' (/home/tales/miniconda3/envs/tf-gpu/lib/python3.11/site-packages/google/protobuf/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47698231",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('emnist/letters', split=['train', 'test'], as_supervised=True, with_info=True)\n",
    "train_dataset, test_dataset = dataset\n",
    "\n",
    "x_train_list, y_train_list = [], []\n",
    "for image, label in tfds.as_numpy(train_dataset):\n",
    "    x_train_list.append(image)\n",
    "    y_train_list.append(label)\n",
    "\n",
    "x_test_list, y_test_list = [], []\n",
    "for image, label in tfds.as_numpy(test_dataset):\n",
    "    x_test_list.append(image)\n",
    "    y_test_list.append(label)\n",
    "\n",
    "x_train = np.array(x_train_list)\n",
    "y_train = np.array(y_train_list)\n",
    "x_test = np.array(x_test_list)\n",
    "y_test = np.array(y_test_list)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28)\n",
    "x_test = x_test.reshape(-1, 28, 28)\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Train: {x_train.shape}, Val: {x_val.shape}, Test: {x_test.shape}\")\n",
    "print(f\"Pixel range: [{x_train.min():.1f}, {x_train.max():.1f}]\")\n",
    "print(f\"Classes: {np.unique(y_train)} (0=A, 25=Z)\")\n",
    "print(f\"Total de samples: {len(x_train) + len(x_val) + len(x_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf87ae",
   "metadata": {},
   "source": [
    "### **1.3. Visualização Exploratória dos Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7af576",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "                'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "fig, axes = plt.subplots(3, 10, figsize=(20, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(26):\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    img = x_train[idx]\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f'{letter_names[i]}', fontsize=12, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "for i in range(26, 30):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Amostras do Dataset EMNIST Letters (A-Z)', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "axes[0].bar([letter_names[i] for i in unique], counts, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Distribuição das Classes (Conjunto de Treino)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Letra', fontsize=11)\n",
    "axes[0].set_ylabel('Frequência', fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "total_samples = len(x_train) + len(x_val) + len(x_test)\n",
    "train_pct = len(x_train) / total_samples * 100\n",
    "val_pct = len(x_val) / total_samples * 100\n",
    "test_pct = len(x_test) / total_samples * 100\n",
    "\n",
    "axes[1].barh(['Dataset'], [train_pct], left=0, label=f'Train ({train_pct:.1f}%)', color='skyblue')\n",
    "axes[1].barh(['Dataset'], [val_pct], left=train_pct, label=f'Val ({val_pct:.1f}%)', color='orange')\n",
    "axes[1].barh(['Dataset'], [test_pct], left=train_pct+val_pct, label=f'Test ({test_pct:.1f}%)', color='lightcoral')\n",
    "axes[1].set_xlabel('Porcentagem (%)', fontsize=11)\n",
    "axes[1].set_title('Divisão Train/Val/Test', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312171d",
   "metadata": {},
   "source": [
    "## **2. Implementação do Variational Autoencoder (VAE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e8503a",
   "metadata": {},
   "source": [
    "### **2.1. Configuração das Topologias para Experimentos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766a266",
   "metadata": {},
   "source": [
    "### **2.2. Treinamento e Seleção da Melhor Topologia**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c3b00d",
   "metadata": {},
   "source": [
    "### **2.3. Análise Comparativa das Topologias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9da9cf",
   "metadata": {},
   "source": [
    "## **3. Exploração do Espaço Latente**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d658844",
   "metadata": {},
   "source": [
    "### **3.1. Projeção do Espaço Latente em 2D (PCA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1d6bdd",
   "metadata": {},
   "source": [
    "### **3.2. Questão 1: Há Formação de Clusters no Espaço Latente?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95dff7",
   "metadata": {},
   "source": [
    "### **3.3. Questão 2: Há Separação dos Rótulos no Espaço Latente?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e564cd",
   "metadata": {},
   "source": [
    "### **3.4. Questão 3: A Projeção Ilustra Quanto da Variância?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9849d96",
   "metadata": {},
   "source": [
    "### **3.5. Interpolação no Espaço Latente**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b00e6",
   "metadata": {},
   "source": [
    "### **3.6. Geração de Novas Amostras**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03d16b",
   "metadata": {},
   "source": [
    "## **4. Avaliação Final e Conclusões**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15901b2",
   "metadata": {},
   "source": [
    "### **4.1. Avaliação no Conjunto de Teste**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cacdb2",
   "metadata": {},
   "source": [
    "### **4.2. Síntese dos Resultados e Conclusões**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
